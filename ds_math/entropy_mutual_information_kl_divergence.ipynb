{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.125  , 0.0625 , 0.03125, 0.03125],\n",
       "       [0.0625 , 0.125  , 0.03125, 0.03125],\n",
       "       [0.0625 , 0.0625 , 0.0625 , 0.0625 ],\n",
       "       [0.25   , 0.     , 0.     , 0.     ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elements of Information Theory, Cover, Thomas Example 2.2.1\n",
    "joint = np.array([[1/8, 1/16, 1/32, 1/32],\n",
    "                  [1/16, 1/8, 1/32, 1/32],\n",
    "                  [1/16, 1/16, 1/16, 1/16],\n",
    "                  [1/4, 0, 0, 0]])\n",
    "joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, q = joint.sum(axis=0), joint.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.75, 2.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entropy(p):\n",
    "    p = np.array(p)\n",
    "    return sum(-p * np.log2(p))\n",
    "\n",
    "entropy(p), entropy(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.75, 2.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.entropy(p, base=2), scipy.stats.entropy(q, base=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL Divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(p, q):\n",
    "    p, q = np.array(p), np.array(q)\n",
    "    sum_ = 0\n",
    "    for i, pi in enumerate(p):\n",
    "        if pi != 0:\n",
    "            sum_ += pi * np.log2(pi/q[i])\n",
    "    return sum_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.25, 0.25)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_divergence(p, q), kl_divergence(q, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.24999999999999997, 0.25)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.entropy(pk=p, qk=q, base=2), scipy.stats.entropy(pk=q, qk=p, base=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mutual information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### definition of mutual information\n",
    "https://en.wikipedia.org/wiki/Mutual_information#Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information(joint):\n",
    "    p, q = joint.sum(axis=0), joint.sum(axis=1)\n",
    "    mi = 0\n",
    "    for i, pi in enumerate(p):\n",
    "        for j, qj in enumerate(q):\n",
    "            if joint[j, i] != 0:\n",
    "                mi += joint[j, i] * np.log2(joint[j, i] / (pi * qj))\n",
    "    return mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elements of Information Theory, Cover, Thomas Example 2.4.1\n",
    "mutual_information(joint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mutual information v.s. KL Divergence\n",
    "\n",
    "Elements of Information Theory, Cover, Thomas (2.29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information_kl(joint):\n",
    "    p, q = joint.sum(axis=0), joint.sum(axis=1)\n",
    "    p_m_q = []\n",
    "    joint_flat = []\n",
    "    for i, pi in enumerate(p):\n",
    "        for j, qj in enumerate(q):\n",
    "            p_m_q.append(pi*qj)\n",
    "            joint_flat.append(joint[j, i])\n",
    "    return kl_divergence(joint_flat, p_m_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutual_information_kl(joint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "- Elements of Information Theory, Cover, Thomas\n",
    "- https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained\n",
    "- https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
