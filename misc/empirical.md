- mini batch size: ...process as many images at a time as our graphics card allows. This is a case of trial and error to find the max batch size - the largest size that doesn't give an out of memory error. https://github.com/fastai/courses/blob/master/deeplearning1/nbs/lesson2.ipynb
- weight decay from regularization: `1 - eta * lambda / n` http://neuralnetworksanddeeplearning.com/chap3.html#overfitting_and_regularization
- There is an additional twist due to how log loss is calculated--log loss rewards predictions that are confident and correct (p=.9999,label=1), but it punishes predictions that are confident and wrong far more (p=.0001,label=1). See visualization below. So to play it safe, we use a sneaky trick to round down our edge predictions. Swap all ones with .95 and all zeros with .05 `isdog = isdog.clip(min=0.05, max=0.95)` https://github.com/fastai/courses/blob/master/deeplearning1/nbs/dogs_cats_redux.ipynb
- A general rule of thumb to keep in mind is that most of our computation time lies in the convolutional layers, while our memory overhead lies in our dense layers. http://wiki.fast.ai/index.php/Lesson_3_Notes
- Last week, we talked about finetuning the Vgg16 model built on Imagenet to classify Cats and Dogs, which involved removing the last fully connected layer and replacing it with one that gave two outputs. We then retrained that last layer to find optimal parameters.
Our philosophy behind doing this was that Vgg16 had learned at a high-level from imagenet how to identify things relevant to making classifications for Cats and Dogs, and we only replaced the last fully connected layer because we wanted to take this knowledge and apply it to this new classification task.
In fine-tuning for a classification task such as Statefarm, we may have to go deeper. The Statefarm dataset tasks you with identifying different activities a distracted driver may be involved in. This is not similar to the original imagenet challenge, and as such it's probably a smart idea to retrain even more fully connected layers. The idea here is that imagenet has learned to identify things that are not useful for classifying driver actions, and we would like to train them further to find things that are useful.
We typically don't touch the convolutional layers, as we find that the filters typically still work well for almost any classification task that uses standard photos. Vision tasks using line art, medical imaging, or other domains very different to standard photos are likely to require retraining convolutional layers, however.
- The general rule of thumb is to have 1/4-1/3 of your batches be psuedo-labeled.
